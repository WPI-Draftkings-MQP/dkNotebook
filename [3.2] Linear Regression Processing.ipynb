{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a Weighted Least Squares to model the time series data to the equation:\n",
    "\\begin{align}\n",
    "y=Ae^{Bx}\n",
    "\\end{align}\n",
    "\n",
    "We feed the time series data into the WLS with varying forgetting factors and recieve an A and B value for the modeled equation for each.\n",
    "\n",
    "The Forgetting Factors are generated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = .1\n",
    "start = 0.\n",
    "Fs = [{'label': 'f1', 'F': 1.}]\n",
    "for i in range(1, 10):\n",
    "    cur = round(start+dif*i, 2)\n",
    "    Fs.append({'label':'f'+str(i+1), 'F':cur})\n",
    "\n",
    "base=.9\n",
    "dif = .9\n",
    "for i in range(0, 5):\n",
    "    dif = dif*.1\n",
    "    base = base + dif\n",
    "    cur = round(base, i+2)\n",
    "    Fs.append({'label':'f'+str(i+11), 'F':cur})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control whether to run on scaled or unscaled data with the following boolean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipywidgets import IntProgress\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkMapDF = pd.read_csv('data/ChunkMap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the A and B values from Ae^Bx for a specific X/Y dataset, based on forgetting factor\n",
    "# Our WLS functions slightly differently for scaled data, in that the forgetting factor is based on the difference\n",
    "# between the current time and final time, as opposed to the normal v\n",
    "def leastSquare(X, Y, F, SCALED_DATA=False):\n",
    "    H_TRANSPOSE = np.vstack(([1.]*len(X), X))\n",
    "    H = np.transpose(H_TRANSPOSE).copy()\n",
    "    currF, i = 1., 0\n",
    "    currF = F\n",
    "    for x in X:\n",
    "        if(SCALED_DATA):\n",
    "            ## We don't want to 'forget' by the number of measurements before the current measurement.\n",
    "            ## Instead, we 'forget' by distance from 100 (aka distance from contest ending) \n",
    "            currF = F**(100-x)\n",
    "        else:\n",
    "            currF = currF*F\n",
    "        H_TRANSPOSE[0][i], H_TRANSPOSE[1][i] = H_TRANSPOSE[0][i]*currF, H_TRANSPOSE[1][i]*currF\n",
    "        i+=1 \n",
    "        \n",
    "    # We use np.linalg.lstsq because unlike .inv and .solve, .lstsq accepts singular matrices,\n",
    "    # however, it is only used when the determinant is 0, otherwise .solve is used\n",
    "    if(np.linalg.det(H_TRANSPOSE @ H) == 0):\n",
    "        return np.linalg.lstsq(H_TRANSPOSE @ H, H_TRANSPOSE @ Y)[0]\n",
    "    else:\n",
    "        return np.linalg.solve(H_TRANSPOSE @ H, H_TRANSPOSE @ Y)\n",
    "\n",
    "def raiseAB(A, B):\n",
    "    return np.exp(A), B\n",
    "\n",
    "def processRegr(X, Y, F, SCALED_DATA=False):\n",
    "    A, B = leastSquare(X, np.log(Y), F, SCALED_DATA=SCALED_DATA)\n",
    "    if(A==\"HTooShort\"):\n",
    "        return A, B\n",
    "    else:\n",
    "        return raiseAB(A, B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438d0cb72a004402a0dbfe865a849007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=65)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contests:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2f6c05f40a42e58202bbf2bbde1c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunkNames = chunkMapDF['Chunk'].unique()[:]\n",
    "\n",
    "chunkBar = IntProgress(min=0, max=len(chunkNames))\n",
    "contestBar = IntProgress(min=0, max=10000)\n",
    "\n",
    "print(\"Chunks:\")\n",
    "display(chunkBar)\n",
    "\n",
    "print(\"Contests:\")\n",
    "display(contestBar)\n",
    "\n",
    "results = []\n",
    "\n",
    "for chunkName in chunkNames[:]:\n",
    "    print(chunkName)\n",
    "    if(scaled):\n",
    "        chunkDF = pd.read_csv('data/Chunks_Scaled/'+chunkName+'.csv')\n",
    "    else:\n",
    "        chunkDF = pd.read_csv('data/Chunks/'+chunkName+'.csv')\n",
    "\n",
    "    contests = chunkDF['ContestId'].unique()[:]\n",
    "    contestBar.value=0\n",
    "    contestBar.max = len(contests)\n",
    "    for cid in contests[:]:\n",
    "        if(scaled):\n",
    "            cSeriesDF = chunkDF[chunkDF['ContestId']==cid]\n",
    "            cSeriesDF = cSeriesDF[cSeriesDF['Before4HoursOut']]\n",
    "            X = cSeriesDF['TimeScaled']\n",
    "            Y = cSeriesDF['EntriesScaled']\n",
    "            X, Y = list(X), list(Y)        \n",
    "            count = 0\n",
    "        else:\n",
    "            cSeriesDF = chunkDF[chunkDF['ContestId']==cid].sort_values(by=['MinutesRemaining'], ascending=False)\n",
    "            numberToRemove = len(cSeriesDF[cSeriesDF['MinutesRemaining']<240])\n",
    "            X = cSeriesDF['MinutesRemaining'].max() - cSeriesDF['MinutesRemaining'][:-numberToRemove]\n",
    "            Y = cSeriesDF['Entries'].cumsum()[:-numberToRemove]\n",
    "            X, Y = list(X), list(Y)   \n",
    "        \n",
    "        contest = {'ContestId':cid}\n",
    "        \n",
    "        for fFactor in Fs[:]:\n",
    "            fName = fFactor['label']\n",
    "            fFactor = fFactor['F']\n",
    "            A, B = 'TooShort', 'TooShort'\n",
    "            if(len(X)>=1):\n",
    "                 A, B  = processRegr(X, Y, fFactor, SCALED_DATA=scaled)\n",
    "            contest[fName+'A'], contest[fName+'B']=A, B    \n",
    "        results.append(contest)\n",
    "        contestBar.value+=1\n",
    "    chunkBar.value+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDF = pd.DataFrame(results).set_index('ContestId')\n",
    "resultsDF.to_csv('data/LR_Values.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

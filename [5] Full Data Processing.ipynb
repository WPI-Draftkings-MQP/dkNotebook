{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure to run Chunking Series and Durations first. This will not be accurate if those files are not up to date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/MetaData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns.drop(\"ContestId\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleColumns = ['EntryFeeAmount', 'TotalPrizeAmount','MaxNumberPlayers', 'MaxEntriesPerUser', 'DistinctUsers', 'NumGames', 'DraftablePlayersInSet','PaidUsersInDraftGroup', 'TopPrize', 'MaxPayoutPosition', 'Duration']\n",
    "categoricalColumns = ['SportName', 'VariantName', 'Contest_Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDF = pd.read_csv('data/WorkingData.csv')\n",
    "rawDF = pd.merge(rawDF, pd.read_csv('data/Durations.csv').set_index('ContestId'), on='ContestId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ContestId', 'DraftGroupId', 'GameSet', 'ContestName',\n",
       "       'ContestStartDatetimeEST', 'ContestEndDatetimeEST',\n",
       "       'ContestPayoutDatetimeEST', 'Entries'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDF.drop(columns=scaleColumns).drop(columns=categoricalColumns).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630446"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575965"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawDF[rawDF['MaxNumberPlayers'] == rawDF['Entries']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDF = rawDF.replace('SOC', 'SOCC')\n",
    "rawDF = rawDF.replace('PGA', 'GOLF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDF = rawDF.copy(deep=True).set_index('ContestId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaColumns = []\n",
    "successCol = []\n",
    "\n",
    "\n",
    "processedDF['Success'] = (processedDF['MaxNumberPlayers'] == processedDF['Entries'])\n",
    "successCol.append('Success')\n",
    "\n",
    "successDF = processedDF[['Success']]\n",
    "\n",
    "for scol in scaleColumns:\n",
    "    processedDF[scol+\"_Scaled\"] = processedDF[scol]/processedDF[scol].max()\n",
    "    metaColumns.append(scol+\"_Scaled\")\n",
    "    \n",
    "for scol in categoricalColumns:\n",
    "    for val in processedDF[scol].unique():\n",
    "        catStr = scol+\"_\"+val\n",
    "        processedDF[catStr] = (processedDF[scol]==val)\n",
    "        metaColumns.append(catStr)\n",
    "        \n",
    "metaDF = processedDF[metaColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaDF.to_csv('data/MetaData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renamePredColumns(df, prefix):\n",
    "    renameDict = {}\n",
    "    columns = []\n",
    "    for col in df.columns:\n",
    "        if(col[:4]=='Pred'):\n",
    "            colName = \"Pred_\"+prefix+\"_\"+col[4:]\n",
    "            renameDict[col] = colName\n",
    "            columns.append(colName)\n",
    "    df = df.rename(columns=renameDict)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameABColumns(df, prefix):\n",
    "    renameDict = {}\n",
    "    columns = []\n",
    "    for col in df.columns:\n",
    "        colName = col\n",
    "        version = 'default'\n",
    "        if(col[-1:][0]=='A'):\n",
    "            version = col[:-1]\n",
    "        elif(col[0] == 'A'):\n",
    "            version = col[1:]\n",
    "        \n",
    "        if(not (version == 'default')):\n",
    "            newName = \"A_\"+prefix+\"_\"+version\n",
    "            renameDict[colName] = newName\n",
    "            renameDict[colName.replace('A', 'B')] = newName.replace('A', 'B')\n",
    "            columns.append(newName)\n",
    "            columns.append(newName.replace('A', 'B'))\n",
    "    df = df.rename(columns=renameDict)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getABDF(dfs):\n",
    "    for df in dfs:\n",
    "        print(len(df))\n",
    "# getABDF([lrDF, kfDF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FLOAT = np.finfo(np.float32).max\n",
    "#Limits columns in a DF to  particular value\n",
    "def limitVal(df, ignore = [], N = MAX_FLOAT):\n",
    "    df = df.copy(deep=True)\n",
    "    for c in df.drop(columns=ignore).columns:\n",
    "#         df[c].loc[df[c] >= N] = N\n",
    "#         print(df[c].dtype)\n",
    "#         if(not (df[c].dtype == 'bool')):\n",
    "        df[c] = df[c].where(df[c] <= N, N) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNSCALED\n",
    "lrDF = pd.read_csv('data/unscaled/LR_Preds.csv').set_index('ContestId').drop(columns=['Duration', 'Unnamed: 0'])\n",
    "lrDF = renamePredColumns(lrDF, 'LR')\n",
    "lrDF = renameABColumns(lrDF, 'LR')\n",
    "\n",
    "kfDF = pd.read_csv('data/unscaled/KF_Preds.csv').set_index('ContestId').drop(columns=['Duration'])\n",
    "kfDF = renamePredColumns(kfDF, 'KF')\n",
    "kfDF = renameABColumns(kfDF, 'KF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF = pd.merge(rawDF, kfDF, on='ContestId', how='left')\n",
    "predDF = pd.merge(predDF, lrDF, on='ContestId', how='left')\n",
    "predDF = predDF.set_index('ContestId')\n",
    "# predDF = pd.merge(predDF, lrDF, on='ContestId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfColumns = []\n",
    "lrColumns = []\n",
    "\n",
    "for col in kfDF.columns:\n",
    "    if(col[:4]=='Pred'):\n",
    "        label = col+\"_Scaled\"\n",
    "        predDF[label] = predDF[col]/predDF[\"MaxNumberPlayers\"]\n",
    "        kfColumns.append(label)\n",
    "    else:\n",
    "        kfColumns.append(col)\n",
    "\n",
    "kfPredsDF = predDF[kfColumns]\n",
    "kfPredsDF = limitVal(kfPredsDF, N=np.finfo(np.float32).max)\n",
    "        \n",
    "for col in lrDF.columns:\n",
    "    if(col[:4]=='Pred'):\n",
    "        label = col+\"_Scaled\"\n",
    "        predDF[label] = predDF[col]/predDF[\"MaxNumberPlayers\"]\n",
    "        lrColumns.append(label)\n",
    "    else:\n",
    "        lrColumns.append(col)\n",
    "        \n",
    "lrPredsDF = predDF[lrColumns]\n",
    "lrPredsDF = limitVal(lrPredsDF, N=np.finfo(np.float32).max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfPredsDF.to_csv('data/unscaled/KF_Results.csv')\n",
    "lrPredsDF.to_csv('data/unscaled/LR_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "workedData = pd.merge(metaDF, kfPredsDF, on='ContestId', how='left')\n",
    "workedData = pd.merge(workedData, lrPredsDF, on='ContestId', how='left')\n",
    "workedData = pd.merge(successDF, workedData, on='ContestId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "workedData.to_csv('data/unscaled/WorkedData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCALED\n",
    "lrDF = pd.read_csv('data/scaled/LR_Preds.csv').set_index('ContestId')#.drop(columns=['Duration', 'Unnamed: 0'])\n",
    "lrDF = renamePredColumns(lrDF, 'LR')\n",
    "lrDF = renameABColumns(lrDF, 'LR')\n",
    "\n",
    "kfDF = pd.read_csv('data/scaled/KF_Preds.csv').set_index('ContestId')\n",
    "kfDF = renamePredColumns(kfDF, 'KF')\n",
    "kfDF = renameABColumns(kfDF, 'KF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF = pd.merge(rawDF, lrDF, on='ContestId', how='left')\n",
    "predDF = pd.merge(predDF, kfDF, on='ContestId', how='left')\n",
    "predDF = predDF.set_index('ContestId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kfColumns = []\n",
    "lrColumns = []\n",
    "\n",
    "for col in kfDF.columns:\n",
    "    if(col[:4]=='Pred'):\n",
    "        label = col+\"_Scaled\"\n",
    "        predDF[label] = predDF[col]/100\n",
    "        kfColumns.append(label)\n",
    "    else:\n",
    "        kfColumns.append(col)\n",
    "\n",
    "kfPredsDF = predDF[kfColumns]\n",
    "kfPredsDF = limitVal(kfPredsDF.dropna())\n",
    "        \n",
    "for col in lrDF.columns:\n",
    "    if(col[:4]=='Pred'):\n",
    "        label = col+\"_Scaled\"\n",
    "        predDF[label] = predDF[col]/100\n",
    "        lrColumns.append(label)\n",
    "    else:\n",
    "        lrColumns.append(col)\n",
    "        \n",
    "lrPredsDF = predDF[lrColumns]\n",
    "lrPredsDF = limitVal(lrPredsDF.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfPredsDF.to_csv('data/scaled/KF_Results.csv')\n",
    "lrPredsDF.to_csv('data/scaled/LR_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "workedData = pd.merge(metaDF, kfPredsDF, on='ContestId', how='left')\n",
    "workedData = pd.merge(workedData, lrPredsDF, on='ContestId', how='left')\n",
    "workedData = pd.merge(successDF, workedData, on='ContestId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "workedData.to_csv('data/scaled/WorkedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
